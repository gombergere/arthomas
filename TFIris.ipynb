{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFIris.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gombergere/arthomas/blob/master/TFIris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnB5cHBRwZhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#http://www.insightsbot.com/blog/2CrCd3/tensorflow-tutorial-iris-classification-with-sgd\n",
        "#Interest of this model : -how to prepare dataset 2 - How to prepare data 3- how to use detailed Tensorflos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZiMoHPVmhs7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import re\n",
        "import seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "#Download the dataset\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "filename = \"raw.csv\"\n",
        "open(filename, 'wb').write(r.content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBoYF7VUmyeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset into memory\n",
        "dataset = pd.read_csv('raw.csv', header=None, names=['sepal_length','sepal_width','petal_length','petal_width','species'])\n",
        "dataset.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlKtj4N3m6ZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot the dataset\n",
        "seaborn.pairplot(dataset, hue=\"species\", size=2, diag_kind=\"kde\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0vheU3nw0jx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "species_lb = LabelBinarizer()\n",
        "Y = species_lb.fit_transform(dataset.species.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfVhcvDWw7lp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "FEATURES = dataset.columns[0:4]\n",
        "X_data = dataset[FEATURES].as_matrix()\n",
        "X_data = normalize(X_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nOZL_VixCiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, Y, test_size=0.3, random_state=1)\n",
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-ZY9AylugUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Parameters\n",
        "learning_rate = 0.01\n",
        "training_epochs = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVqW_r3kuvL_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Neural Network Parameters\n",
        "n_hidden_1 = 256 # 1st layer number of neurons\n",
        "n_hidden_2 = 128 # 1st layer number of neurons\n",
        "n_input = X_train.shape[1] # input shape (105, 4)\n",
        "n_classes = y_train.shape[1] # classes to predict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Md8kY2mu-4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inputs\n",
        "X = tf.placeholder(\"float\", shape=[None, n_input])\n",
        "y = tf.placeholder(\"float\", shape=[None, n_classes])\n",
        "\n",
        "# Dictionary of Weights and Biases\n",
        "weights = {\n",
        "  'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
        "  'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
        "  'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
        "}\n",
        "\n",
        "biases = {\n",
        "  'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
        "  'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
        "  'out': tf.Variable(tf.random_normal([n_classes]))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75UrJ-vwvA7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model Forward Propagation step\n",
        "def forward_propagation(x):\n",
        "    # Hidden layer1\n",
        "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    \n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
        "    layer_2 = tf.nn.relu(layer_2)\n",
        "\n",
        "    # Output fully connected layer\n",
        "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out'] \n",
        "    return out_layer\n",
        "\n",
        "\n",
        "# Model Outputs\n",
        "yhat = forward_propagation(X)\n",
        "ypredict = tf.argmax(yhat, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIVPRkT0vNN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Backward propagation\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=yhat))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "#optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19MAkPKDvTaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initializing the variables\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "from datetime import datetime\n",
        "startTime = datetime.now()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    \n",
        "    #writer.add_graph(sess.graph)\n",
        "    #EPOCHS\n",
        "    for epoch in range(training_epochs):\n",
        "        #Stochasting Gradient Descent\n",
        "        for i in range(len(X_train)):\n",
        "            summary = sess.run(train_op, feed_dict={X: X_train[i: i + 1], y: y_train[i: i + 1]})\n",
        "        \n",
        "        train_accuracy = np.mean(np.argmax(y_train, axis=1) == sess.run(ypredict, feed_dict={X: X_train, y: y_train}))\n",
        "        test_accuracy  = np.mean(np.argmax(y_test, axis=1) == sess.run(ypredict, feed_dict={X: X_test, y: y_test}))\n",
        "                \n",
        "        print(\"Epoch = %d, train accuracy = %.2f%%, test accuracy = %.2f%%\" % (epoch + 1, 100. * train_accuracy, 100. * test_accuracy))\n",
        "        #print(\"Epoch = %d, train accuracy = %.2f%%\" % (epoch + 1, 100. * train_accuracy))\n",
        "\n",
        "    sess.close()\n",
        "print(\"Time taken:\", datetime.now() - startTime)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}