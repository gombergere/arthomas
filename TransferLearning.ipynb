{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransferLearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gombergere/arthomas/blob/master/TransferLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frXXrGUaiacc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://machinelearningmastery.com/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models/\n",
        "#Article tres interessant. Il montre deja comment initialiser un modele Keras\n",
        "#...comment utiliser les modeles de reference de la reconnaissance d'images\n",
        "#...comment utiliser les fonctions de traitement et d'affichage d'images\n",
        "#...et évidemment coment utiliser un modéle déja entraine pour lui faire recoonaitre de nouvelles images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rtj6_rmyWX7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.applications import imagenet_utils\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras.preprocessing import image\n",
        "image.ImageDataGenerator()\n",
        "image.load_img()\n",
        "\n",
        "mobile =keras.applications.mobilenet.MobileNet()\n",
        "\n",
        "def prepare_image(file):\n",
        "    img_path = 'MobileNet-inference-images/'\n",
        "    img = image.load_img(img_path + file, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
        "    return \n",
        "    keras.applications.mobilenet.preprocess_imput(img_array_expanded_dims)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQrEWaVDkTWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "file=files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1okXHnPDkWV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import image\n",
        "# and use \n",
        "image.ImageDataGenerator()\n",
        "image.load_img('dog.jpg', target_size=(224, 224))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2OAlrKZTRiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# example of loading the vgg16 model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "# load model\n",
        "model = VGG16()\n",
        "# summarize the model\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Scyql-MUHpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# example of loading the inception v3 model\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "# load model\n",
        "model = InceptionV3()\n",
        "# summarize the model\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2p_BJYdURgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# example of loading the resnet50 model\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "# load model\n",
        "model = ResNet50()\n",
        "# summarize the model\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFogPhPKUxu3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "file=files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEvcqSf0Vd45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import image\n",
        "# and use \n",
        "image.ImageDataGenerator()\n",
        "image.load_img('dog2.jpg', target_size=(224, 224))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wjs7cDcaaBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# example of loading the vgg16 model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "# load model\n",
        "model = VGG16()\n",
        "# summarize the model\n",
        "model.summary()\n",
        "model = VGG16()\n",
        "# remove the output layer\n",
        "model.layers.pop()\n",
        "model = Model(inputs=model.inputs, outputs=model.layers[-1].output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMgfPfHwa-Pf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get extracted features\n",
        "#predictFromImage(image)\n",
        "features = model.predict(image)\n",
        "print(features.shape)\n",
        "# save to file\n",
        "dump(features, open('dog.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i9xjKBGcS42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# example of using the vgg16 model as a feature extraction model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.vgg16 import decode_predictions\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "from pickle import dump\n",
        "# load an image from file\n",
        "image = load_img('dog.jpg', target_size=(224, 224))\n",
        "# convert the image pixels to a numpy array\n",
        "image = img_to_array(image)\n",
        "# reshape data for the model\n",
        "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "# prepare the image for the VGG model\n",
        "image = preprocess_input(image)\n",
        "# load model\n",
        "model = VGG16()\n",
        "# remove the output layer\n",
        "model.layers.pop()\n",
        "model = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
        "# get extracted features\n",
        "features = model.predict(image)\n",
        "print(features.shape)\n",
        "# save to file\n",
        "dump(features, open('dog.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WImG4Uiudpcd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# example of using a pre-trained model as a classifier\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.vgg16 import decode_predictions\n",
        "from keras.applications.vgg16 import VGG16\n",
        "# load an image from file\n",
        "image = load_img('dog.jpg', target_size=(224, 224))\n",
        "# convert the image pixels to a numpy array\n",
        "image = img_to_array(image)\n",
        "# reshape data for the model\n",
        "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "# prepare the image for the VGG model\n",
        "image = preprocess_input(image)\n",
        "# load the model\n",
        "model = VGG16()\n",
        "# predict the probability across all output classes\n",
        "yhat = model.predict(image)\n",
        "# convert the probabilities to class labels\n",
        "label = decode_predictions(yhat)\n",
        "# retrieve the most likely result, e.g. highest probability\n",
        "label = label[0][0]\n",
        "# print the classification\n",
        "print('%s (%.2f%%)' % (label[1], label[2]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pf6Ixfd3d5bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# example of tending the vgg16 model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "# load model without classifier layers\n",
        "model = VGG16(include_top=False, input_shape=(300, 300, 3))\n",
        "# add new classifier layers\n",
        "flat1 = Flatten()(model.outputs)\n",
        "class1 = Dense(1024, activation='relu')(flat1)\n",
        "output = Dense(10, activation='softmax')(class1)\n",
        "# define new model\n",
        "model = Model(inputs=model.inputs, outputs=output)\n",
        "# summarize\n",
        "model.summary()\n",
        "# ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzSxQkH8ekfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load model without classifier layers\n",
        "model = VGG16(include_top=False, input_shape=(300, 300, 3))\n",
        "# mark loaded layers as not trainable\n",
        "for layer in model.layers:\n",
        "\tlayer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWVVEZUqen2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load model without classifier layers\n",
        "model = VGG16(include_top=False, input_shape=(300, 300, 3))\n",
        "# mark some layers as not trainable\n",
        "model.get_layer('block1_conv1').trainable = False\n",
        "model.get_layer('block1_conv2').trainable = False\n",
        "model.get_layer('block2_conv1').trainable = False\n",
        "model.get_layer('block2_conv2').trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}